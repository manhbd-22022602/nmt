{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T10:52:56.402458Z",
     "iopub.status.busy": "2024-07-25T10:52:56.402152Z",
     "iopub.status.idle": "2024-07-25T10:52:59.099115Z",
     "shell.execute_reply": "2024-07-25T10:52:59.098356Z",
     "shell.execute_reply.started": "2024-07-25T10:52:56.402412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "rm: cannot remove '/kaggle/working/nmt': No such file or directory\r\n",
      "Cloning into 'nmt'...\r\n",
      "remote: Enumerating objects: 91, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (91/91), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (62/62), done.\u001b[K\r\n",
      "remote: Total 91 (delta 27), reused 87 (delta 23), pack-reused 0\u001b[K\r\n",
      "Unpacking objects: 100% (91/91), done.\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working\n",
    "!rm -r /kaggle/working/nmt\n",
    "!git clone https://github.com/manhbd-22022602/nmt.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T10:52:59.100964Z",
     "iopub.status.busy": "2024-07-25T10:52:59.100719Z",
     "iopub.status.idle": "2024-07-25T10:52:59.105964Z",
     "shell.execute_reply": "2024-07-25T10:52:59.105283Z",
     "shell.execute_reply.started": "2024-07-25T10:52:59.100925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/nmt\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T10:52:59.107816Z",
     "iopub.status.busy": "2024-07-25T10:52:59.107258Z",
     "iopub.status.idle": "2024-07-25T11:15:11.885133Z",
     "shell.execute_reply": "2024-07-25T11:15:11.884203Z",
     "shell.execute_reply.started": "2024-07-25T10:52:59.107678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\r\n",
      "For more information, please see:\r\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n",
      "  * https://github.com/tensorflow/addons\r\n",
      "If you depend on functionality not listed there, please file an issue.\r\n",
      "\r\n",
      "# Job id 0\r\n",
      "# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 3651322341039662075), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 10620513112374416575), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 2897360863304890678), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 15883691623, 13164963973814144070)]\r\n",
      "# Vocab file /kaggle/input/en-vi-small/vocab.en exists\r\n",
      "# Vocab file /kaggle/input/en-vi-small/vocab.vi exists\r\n",
      "  saving hparams to /kaggle/working/nmt/hparams\r\n",
      "  saving hparams to /kaggle/working/nmt/best_bleu/hparams\r\n",
      "  attention=\r\n",
      "  attention_architecture=standard\r\n",
      "  avg_ckpts=False\r\n",
      "  batch_size=128\r\n",
      "  beam_width=5\r\n",
      "  best_bleu=0\r\n",
      "  best_bleu_dir=/kaggle/working/nmt/best_bleu\r\n",
      "  check_special_token=True\r\n",
      "  colocate_gradients_with_ops=True\r\n",
      "  coverage_penalty_weight=0.0\r\n",
      "  decay_scheme=luong234\r\n",
      "  dev_prefix=/kaggle/input/en-vi-small/val/tst2012\r\n",
      "  dropout=0.2\r\n",
      "  embed_prefix=None\r\n",
      "  encoder_type=bi\r\n",
      "  eos=</s>\r\n",
      "  epoch_step=0\r\n",
      "  forget_bias=1.0\r\n",
      "  infer_batch_size=32\r\n",
      "  infer_mode=beam_search\r\n",
      "  init_op=uniform\r\n",
      "  init_weight=0.1\r\n",
      "  language_model=False\r\n",
      "  learning_rate=0.001\r\n",
      "  length_penalty_weight=0.0\r\n",
      "  log_device_placement=False\r\n",
      "  max_gradient_norm=5.0\r\n",
      "  max_train=0\r\n",
      "  metrics=['bleu']\r\n",
      "  num_buckets=5\r\n",
      "  num_dec_emb_partitions=0\r\n",
      "  num_decoder_layers=2\r\n",
      "  num_decoder_residual_layers=0\r\n",
      "  num_embeddings_partitions=0\r\n",
      "  num_enc_emb_partitions=0\r\n",
      "  num_encoder_layers=2\r\n",
      "  num_encoder_residual_layers=0\r\n",
      "  num_gpus=1\r\n",
      "  num_inter_threads=0\r\n",
      "  num_intra_threads=0\r\n",
      "  num_keep_ckpts=5\r\n",
      "  num_sampled_softmax=0\r\n",
      "  num_train_steps=12000\r\n",
      "  num_translations_per_input=1\r\n",
      "  num_units=512\r\n",
      "  optimizer=adam\r\n",
      "  out_dir=/kaggle/working/nmt\r\n",
      "  output_attention=True\r\n",
      "  override_loaded_hparams=False\r\n",
      "  pass_hidden_state=True\r\n",
      "  random_seed=None\r\n",
      "  residual=False\r\n",
      "  sampling_temperature=0.0\r\n",
      "  share_vocab=False\r\n",
      "  sos=<s>\r\n",
      "  src=en\r\n",
      "  src_embed_file=\r\n",
      "  src_max_len=50\r\n",
      "  src_max_len_infer=None\r\n",
      "  src_vocab_file=/kaggle/input/en-vi-small/vocab.en\r\n",
      "  src_vocab_size=17192\r\n",
      "  steps_per_external_eval=None\r\n",
      "  steps_per_stats=1000\r\n",
      "  subword_option=\r\n",
      "  test_prefix=/kaggle/input/en-vi-small/test/tst2013\r\n",
      "  tgt=vi\r\n",
      "  tgt_embed_file=\r\n",
      "  tgt_max_len=50\r\n",
      "  tgt_max_len_infer=None\r\n",
      "  tgt_vocab_file=/kaggle/input/en-vi-small/vocab.vi\r\n",
      "  tgt_vocab_size=7710\r\n",
      "  time_major=True\r\n",
      "  train_prefix=/kaggle/input/en-vi-small/train/train\r\n",
      "  unit_type=lstm\r\n",
      "  use_char_encode=False\r\n",
      "  vocab_prefix=/kaggle/input/en-vi-small/vocab\r\n",
      "  warmup_scheme=t2t\r\n",
      "  warmup_steps=0\r\n",
      "WARNING:tensorflow:From /kaggle/working/nmt/nmt/utils/iterator_utils.py:129: DatasetV1.shard (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use `dataset.apply(tf.data.experimental.filter_for_shard(...))`.\r\n",
      "WARNING:tensorflow:From /kaggle/working/nmt/nmt/utils/iterator_utils.py:235: group_by_window (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use `tf.data.experimental.group_by_window(...)`.\r\n",
      "WARNING:tensorflow:From /kaggle/working/nmt/nmt/utils/iterator_utils.py:228: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use tf.cast instead.\r\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Colocations handled automatically by placer.\r\n",
      "# Creating train graph ...\r\n",
      "# Build a basic encoder\r\n",
      "  num_bi_layers = 1, num_bi_residual_layers=0\r\n",
      "  cell 0  LSTM, forget_bias=1WARNING:tensorflow:From /kaggle/working/nmt/nmt/model_helper.py:402: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\r\n",
      "  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\r\n",
      "  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\r\n",
      "WARNING:tensorflow:From /kaggle/working/nmt/nmt/model.py:843: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\r\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\r\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use tf.cast instead.\r\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\r\n",
      "WARNING:tensorflow:From /kaggle/working/nmt/nmt/model.py:445: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use tf.cast instead.\r\n",
      "  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\r\n",
      "  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\r\n",
      "WARNING:tensorflow:From /kaggle/working/nmt/nmt/model_helper.py:508: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\r\n",
      "  learning_rate=0.001, warmup_steps=0, warmup_scheme=t2t\r\n",
      "  decay_scheme=luong234, start_decay_step=8000, decay_steps 1000, decay_factor 0.5\r\n",
      "# Trainable variables\r\n",
      "Format: <name>, <shape>, <(soft) device placement>\r\n",
      "  embeddings/encoder/embedding_encoder:0, (17192, 512), /device:GPU:0\r\n",
      "  embeddings/decoder/embedding_decoder:0, (7710, 512), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 7710), /device:GPU:0\r\n",
      "# Creating eval graph ...\r\n",
      "# Build a basic encoder\r\n",
      "  num_bi_layers = 1, num_bi_residual_layers=0\r\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\r\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\r\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\r\n",
      "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\r\n",
      "# Trainable variables\r\n",
      "Format: <name>, <shape>, <(soft) device placement>\r\n",
      "  embeddings/encoder/embedding_encoder:0, (17192, 512), /device:GPU:0\r\n",
      "  embeddings/decoder/embedding_decoder:0, (7710, 512), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 7710), /device:GPU:0\r\n",
      "# Creating infer graph ...\r\n",
      "# Build a basic encoder\r\n",
      "  num_bi_layers = 1, num_bi_residual_layers=0\r\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\r\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\r\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\r\n",
      "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\r\n",
      "  decoder: infer_mode=beam_searchbeam_width=5, length_penalty=0.000000, coverage_penalty=0.000000\r\n",
      "# Trainable variables\r\n",
      "Format: <name>, <shape>, <(soft) device placement>\r\n",
      "  embeddings/encoder/embedding_encoder:0, (17192, 512), /device:GPU:0\r\n",
      "  embeddings/decoder/embedding_decoder:0, (7710, 512), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 7710), \r\n",
      "# log_file=/kaggle/working/nmt/log_1721911439\r\n",
      "  created train model with fresh parameters, time 2.00s\r\n",
      "  created infer model with fresh parameters, time 0.12s\r\n",
      "  # 60\r\n",
      "    src: I didn &apos;t know how to use the cutlery .\r\n",
      "    ref: Tôi không biết cách dùng thìa dĩa .\r\n",
      "    nmt: Chàng Chàng Chàng Chàng Chàng án án án án án án án án Hân thi thi thi thi Giao Giao\r\n",
      "  created eval model with fresh parameters, time 0.10s\r\n",
      "  eval dev: perplexity 7872.32, time 0s, Thu Jul 25 12:44:04 2024.\r\n",
      "  eval test: perplexity 7883.82, time 0s, Thu Jul 25 12:44:05 2024.\r\n",
      "  created infer model with fresh parameters, time 0.11s\r\n",
      "# Start step 0, lr 0.001, Thu Jul 25 12:44:05 2024\r\n",
      "# Init train iterator, skipping 0 elements\r\n",
      "  step 1000 lr 0.001 step-time 0.12s wps 46.62K ppl 116.46 gN 8.55 bleu 0.00, Thu Jul 25 12:46:06 2024\r\n",
      "# Finished an epoch, step 1043. Perform external evaluation\r\n",
      "  created infer model with fresh parameters, time 0.12s\r\n",
      "  # 768\r\n",
      "    src: Slowly but surely , it lifted .\r\n",
      "    ref: Chậm nhưng chắc , cảm giác nhẹ dần .\r\n",
      "    nmt: nhói 1800 1800 1800 giềng béo béo béo Jody Jody Jody Jody Jody Jody\r\n",
      "  created infer model with fresh parameters, time 0.12s\r\n",
      "  step 2000 lr 0.001 step-time 0.12s wps 46.48K ppl 41.56 gN 7.16 bleu 0.00, Thu Jul 25 12:48:07 2024\r\n",
      "# Finished an epoch, step 2086. Perform external evaluation\r\n",
      "  created infer model with fresh parameters, time 0.12s\r\n",
      "  # 1339\r\n",
      "    src: We &apos;ve all got navigation controls in our car .\r\n",
      "    ref: Chúng ta đều có thiết bị định vị trong xe .\r\n",
      "    nmt: chuẩn vựng vựng vựng vựng Ghraib Ghraib Ghraib giám giám AO AO AO AO AO AO báo báo báo báo\r\n",
      "  created infer model with fresh parameters, time 0.12s\r\n",
      "  step 3000 lr 0.001 step-time 0.12s wps 47.18K ppl 28.38 gN 7.03 bleu 0.00, Thu Jul 25 12:50:07 2024\r\n",
      "# Finished an epoch, step 3129. Perform external evaluation\r\n",
      "  created infer model with fresh parameters, time 0.14s\r\n",
      "  # 1448\r\n",
      "    src: Green is output , blue is power , pink is input and orange is wire .\r\n",
      "    ref: Xanh lá cây là đầu ra , xanh biển là nguồn điện , hồng là đầu vào và da cam là dây dẫn .\r\n",
      "    nmt: Harlem Hộp Hộp Hộp 1966 vãn vãn IMF hăm nghiên bỗng bỗng bỗng nghiên nghiên nghiên nghiên Ê Ê Ê Ê rô-bốt Ê Ê Ê Ê Ê mô-men mô-men mô-men mô-men mô-men\r\n",
      "  created infer model with fresh parameters, time 0.13s\r\n",
      "  step 4000 lr 0.001 step-time 0.12s wps 47.92K ppl 22.16 gN 7.05 bleu 0.00, Thu Jul 25 12:52:05 2024\r\n",
      "# Finished an epoch, step 4172. Perform external evaluation\r\n",
      "  created infer model with fresh parameters, time 0.13s\r\n",
      "  # 908\r\n",
      "    src: And who could have predicted any of this ?\r\n",
      "    ref: Và ai có thể dự đoán bất cứ gì về điều này ?\r\n",
      "    nmt: 80,000 80,000 80,000 Vật Vật Vật 80,000 Vật Vật Vật cặn thọ Clinton Clinton Clinton Clinton Clinton Clinton\r\n",
      "  created infer model with fresh parameters, time 0.12s\r\n",
      "  step 5000 lr 0.001 step-time 0.12s wps 47.84K ppl 18.28 gN 7.09 bleu 0.00, Thu Jul 25 12:54:02 2024\r\n",
      "# Finished an epoch, step 5215. Perform external evaluation\r\n",
      "  created infer model with fresh parameters, time 0.11s\r\n",
      "  # 874\r\n",
      "    src: And he had posted lots of nature videos in fact .\r\n",
      "    ref: Thực ra ông ấy đã đăng rất nhiều video về thiên nhiên .\r\n",
      "    nmt: Jurvetson rễ rễ rễ rễ rễ rễ Giờ protêin protêin cùa cùa cùa cùa cùa cùa cùa cùa cùa cùa cùa cùa\r\n",
      "  created infer model with fresh parameters, time 0.12s\r\n",
      "  step 6000 lr 0.001 step-time 0.12s wps 48.38K ppl 15.75 gN 7.19 bleu 0.00, Thu Jul 25 12:55:59 2024\r\n",
      "# Finished an epoch, step 6258. Perform external evaluation\r\n",
      "  created infer model with fresh parameters, time 0.13s\r\n",
      "  # 462\r\n",
      "    src: It was not drowned yet .\r\n",
      "    ref: Nó vẫn chưa bị ngộp\r\n",
      "    nmt: xóc vú vú vú vú vú Biển Biển Vườn Vườn Vườn chế\r\n",
      "  created infer model with fresh parameters, time 0.14s\r\n",
      "  step 7000 lr 0.001 step-time 0.12s wps 47.15K ppl 13.97 gN 7.33 bleu 0.00, Thu Jul 25 12:57:59 2024\r\n",
      "# Finished an epoch, step 7301. Perform external evaluation\r\n",
      "  created infer model with fresh parameters, time 0.14s\r\n",
      "  # 1375\r\n",
      "    src: When I say realism , I mean photo-realism .\r\n",
      "    ref: Khi tôi nói tính chân thực , ý ́ tôi là tính chân thực của ảnh .\r\n",
      "    nmt: lượm Trân TD TD TD TD vầng vầng thua thua thua ngộ ngộ ngộ ngộ Rằng Rằng Rằng\r\n",
      "  created infer model with fresh parameters, time 0.13s\r\n",
      "  step 8000 lr 0.001 step-time 0.12s wps 47.34K ppl 12.53 gN 7.43 bleu 0.00, Thu Jul 25 12:59:58 2024\r\n",
      "# Finished an epoch, step 8344. Perform external evaluation\r\n",
      "  created infer model with fresh parameters, time 0.13s\r\n",
      "  # 466\r\n",
      "    src: We transform the world , but we don &apos;t remember it .\r\n",
      "    ref: Chúng ta biến đổi thế giới nhưng chúng ta lại không nhớ điều này\r\n",
      "    nmt: Bilbao 1100 1100 Cháu Cháu Cháu Cháu Ngành Bergen F F F F F gấp gấp gấp bẩn bẩn bẩn va va va va\r\n",
      "  created infer model with fresh parameters, time 0.13s\r\n",
      "  step 9000 lr 0.001 step-time 0.12s wps 47.59K ppl 11.45 gN 7.52 bleu 0.00, Thu Jul 25 13:01:56 2024\r\n",
      "# Finished an epoch, step 9387. Perform external evaluation\r\n",
      "  created infer model with fresh parameters, time 0.12s\r\n",
      "  # 450\r\n",
      "    src: And I went sailing on it , and we did surveys throughout the southern South China sea and especially the Java Sea .\r\n",
      "    ref: Tôi dùng nó để làm các cuộc khảo sát xuyên suốt vùng phía Nam của biển Nam Hải Trung Quốc và đặc biệt vùng biển Java .\r\n",
      "    nmt: Bàn Bàn chanh Elliot Elliot Elliot í í í í í í í í í Hadron Hadron Hadron Hadron Hadron đậy đậy cư đậy đậy đậy đậy đậy Mozambique Mozambique Mozambique Mừng Mừng Mừng Mừng Mừng Mừng Talk Mừng Đạo Đạo Đạo Đạo Đạo Đạo Đạo\r\n",
      "  created infer model with fresh parameters, time 0.13s\r\n",
      "  step 10000 lr 0.0005 step-time 0.12s wps 48.55K ppl 9.95 gN 7.41 bleu 0.00, Thu Jul 25 13:03:52 2024\r\n",
      "# Save eval, global step 10000\r\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use standard file APIs to check for files with this prefix.\r\n",
      "  loaded infer model parameters from /kaggle/working/nmt/translate.ckpt-10000, time 0.14s\r\n",
      "  # 448\r\n",
      "    src: Fish development meant imposing on countries that had already 100,000 fishers to impose on them industrial fishing .\r\n",
      "    ref: Phát triển ngành đánh bắt cá điều đó có nghĩa là áp đặt lên những quốc gia đó những nước mà đã có 100,000 ngư dân áp đặt ngành công nhiệp đánh bắt cá lên họ\r\n",
      "    nmt: Cộng sản của chúng tôi đã xây dựng những đất nước đang làm việc với những con đường sau khi họ phải xây dựng những rào cản của họ .\r\n",
      "  loaded eval model parameters from /kaggle/working/nmt/translate.ckpt-10000, time 0.12s\r\n",
      "  eval dev: perplexity 27.53, time 0s, Thu Jul 25 13:03:54 2024.\r\n",
      "  eval test: perplexity 30.13, time 0s, Thu Jul 25 13:03:55 2024.\r\n",
      "# Finished an epoch, step 10430. Perform external evaluation\r\n",
      "  loaded infer model parameters from /kaggle/working/nmt/translate.ckpt-10000, time 0.10s\r\n",
      "  # 1085\r\n",
      "    src: Now the transition point happened when these communities got so close that , in fact , they got together and decided to write down the whole recipe for the community together on one string of DNA .\r\n",
      "    ref: Thời điểm chuyển giao xảy ra khi những cộng đồng ấy gần gũi với nhau đến mức , trong thực tế , chúng cùng nhau hình thành nên một công thức cấu tạo chung cho cả quần thể trên một dãy ADN duy nhất .\r\n",
      "    nmt: <unk> giờ , mục đích thực sự xảy ra với cộng đồng này , ngay cả khi chúng tôi làm việc cùng nhau , chúng tôi đã chia sẻ nó thành các loại công cụ cho phép ẩn dụ trong cộng đồng <unk>\r\n",
      "  loaded infer model parameters from /kaggle/working/nmt/translate.ckpt-10000, time 0.10s\r\n",
      "# External evaluation, global step 10000\r\n",
      "  decoding to output /kaggle/working/nmt/output_dev\r\n",
      "  done, num sentences 1553, num translations per input 1, time 8s, Thu Jul 25 13:04:49 2024.\r\n",
      "  bleu dev: 10.0\r\n",
      "  saving hparams to /kaggle/working/nmt/hparams\r\n",
      "# External evaluation, global step 10000\r\n",
      "  decoding to output /kaggle/working/nmt/output_test\r\n",
      "  done, num sentences 1268, num translations per input 1, time 7s, Thu Jul 25 13:04:57 2024.\r\n",
      "  bleu test: 9.6\r\n",
      "  saving hparams to /kaggle/working/nmt/hparams\r\n",
      "  step 11000 lr 0.00025 step-time 0.12s wps 47.26K ppl 8.99 gN 7.47 bleu 10.00, Thu Jul 25 13:06:12 2024\r\n",
      "# Finished an epoch, step 11473. Perform external evaluation\r\n",
      "  loaded infer model parameters from /kaggle/working/nmt/translate.ckpt-10000, time 0.10s\r\n",
      "  # 1122\r\n",
      "    src: And the next steps , like nervous systems and brains , took a few hundred million years .\r\n",
      "    ref: Và những giai đoạn tiếp theo , như hệ thống thần kinh và não bộ , mất vài trăm triệu năm .\r\n",
      "    nmt: <unk> bước tiếp theo , như thế , và hệ thống não bộ , và vài triệu , 10 triệu <unk>\r\n",
      "  loaded infer model parameters from /kaggle/working/nmt/translate.ckpt-10000, time 0.11s\r\n",
      "# External evaluation, global step 10000\r\n",
      "  decoding to output /kaggle/working/nmt/output_dev\r\n",
      "  done, num sentences 1553, num translations per input 1, time 8s, Thu Jul 25 13:07:09 2024.\r\n",
      "  bleu dev: 10.0\r\n",
      "  saving hparams to /kaggle/working/nmt/hparams\r\n",
      "# External evaluation, global step 10000\r\n",
      "  decoding to output /kaggle/working/nmt/output_test\r\n",
      "  done, num sentences 1268, num translations per input 1, time 7s, Thu Jul 25 13:07:17 2024.\r\n",
      "  bleu test: 9.6\r\n",
      "  saving hparams to /kaggle/working/nmt/hparams\r\n",
      "  step 12000 lr 0.000125 step-time 0.12s wps 47.79K ppl 8.49 gN 7.49 bleu 10.00, Thu Jul 25 13:08:26 2024\r\n",
      "  loaded infer model parameters from /kaggle/working/nmt/translate.ckpt-12000, time 0.11s\r\n",
      "  # 1466\r\n",
      "    src: So for example , we &apos;ve had designers with no experience with electronics whatsoever start to play with littleBits as a material .\r\n",
      "    ref: Ví dụ như ở đây chúng tôi có những nhà thiết kế mà hoàn toàn không biết chút gì về điện tử bắt đầu chơi với littleBits như công cụ sáng tạo .\r\n",
      "    nmt: <unk> vậy , chúng tôi , chúng tôi đã thiết kế một nhà khoa học với những thiết bị điện tử mà không có động vật nào để chơi với một vật liệu <unk>\r\n",
      "  loaded eval model parameters from /kaggle/working/nmt/translate.ckpt-12000, time 0.10s\r\n",
      "  eval dev: perplexity 28.71, time 0s, Thu Jul 25 13:08:28 2024.\r\n",
      "  eval test: perplexity 32.06, time 0s, Thu Jul 25 13:08:29 2024.\r\n",
      "  loaded infer model parameters from /kaggle/working/nmt/translate.ckpt-12000, time 0.10s\r\n",
      "# External evaluation, global step 12000\r\n",
      "  decoding to output /kaggle/working/nmt/output_dev\r\n",
      "  done, num sentences 1553, num translations per input 1, time 8s, Thu Jul 25 13:08:37 2024.\r\n",
      "  bleu dev: 10.2\r\n",
      "  saving hparams to /kaggle/working/nmt/hparams\r\n",
      "# External evaluation, global step 12000\r\n",
      "  decoding to output /kaggle/working/nmt/output_test\r\n",
      "  done, num sentences 1268, num translations per input 1, time 7s, Thu Jul 25 13:08:45 2024.\r\n",
      "  bleu test: 9.6\r\n",
      "  saving hparams to /kaggle/working/nmt/hparams\r\n",
      "# Final, step 12000 lr 0.000125 step-time 0.12s wps 47.79K ppl 8.49 gN 7.49 dev ppl 28.71, dev bleu 10.2, test ppl 32.06, test bleu 9.6, Thu Jul 25 13:08:46 2024\r\n",
      "# Done training!, time 1480s, Thu Jul 25 13:08:46 2024.\r\n",
      "# Start evaluating saved best models.\r\n",
      "  loaded infer model parameters from /kaggle/working/nmt/best_bleu/translate.ckpt-12000, time 0.11s\r\n",
      "  # 1274\r\n",
      "    src: And it could have connected them with government services if they &apos;d been needed , but a neighbor is a far better and cheaper alternative to government services .\r\n",
      "    ref: Nếu cần thiết , các dịch vụ của chính phủ có thể giúp đỡ họ kết nối lại , nhưng một người hàng xóm thì là một giải pháp tốt và tiết kiệm hơn so với các dịch vụ của chính phủ .\r\n",
      "    nmt: Và nó có thể giúp chúng ta thiết kế một dịch vụ cho chính phủ mà chúng ta đang làm , nhưng nếu giá trị của Hoa Kỳ sẽ trở nên rẻ hơn và rẻ tiền hơn .\r\n",
      "  loaded eval model parameters from /kaggle/working/nmt/best_bleu/translate.ckpt-12000, time 0.09s\r\n",
      "  eval dev: perplexity 28.71, time 0s, Thu Jul 25 13:08:47 2024.\r\n",
      "  eval test: perplexity 32.06, time 0s, Thu Jul 25 13:08:48 2024.\r\n",
      "  loaded infer model parameters from /kaggle/working/nmt/best_bleu/translate.ckpt-12000, time 0.11s\r\n",
      "# External evaluation, global step 12000\r\n",
      "  decoding to output /kaggle/working/nmt/output_dev\r\n",
      "  done, num sentences 1553, num translations per input 1, time 8s, Thu Jul 25 13:08:56 2024.\r\n",
      "  bleu dev: 10.2\r\n",
      "  saving hparams to /kaggle/working/nmt/hparams\r\n",
      "# External evaluation, global step 12000\r\n",
      "  decoding to output /kaggle/working/nmt/output_test\r\n",
      "  done, num sentences 1268, num translations per input 1, time 7s, Thu Jul 25 13:09:04 2024.\r\n",
      "  bleu test: 9.6\r\n",
      "  saving hparams to /kaggle/working/nmt/hparams\r\n",
      "# Best bleu, step 12000 lr 0.000125 step-time 0.12s wps 47.79K ppl 8.49 gN 7.49 dev ppl 28.71, dev bleu 10.2, test ppl 32.06, test bleu 9.6, Thu Jul 25 13:09:05 2024\r\n"
     ]
    }
   ],
   "source": [
    "!python -m nmt.nmt \\\n",
    "    --src=en --tgt=vi \\\n",
    "    --vocab_prefix=/kaggle/input/en-vi-small/vocab \\\n",
    "    --train_prefix=/kaggle/input/en-vi-small/train/train \\\n",
    "    --dev_prefix=/kaggle/input/en-vi-small/val/tst2012 \\\n",
    "    --test_prefix=/kaggle/input/en-vi-small/test/tst2013 \\\n",
    "    --out_dir=/kaggle/working/nmt \\\n",
    "    --num_train_steps=12000 \\\n",
    "    --steps_per_stats=1000 \\\n",
    "    --num_layers=2 \\\n",
    "    --num_units=512 \\\n",
    "    --dropout=0.2 \\\n",
    "    --encoder_type=bi \\\n",
    "    --unit_type=lstm \\\n",
    "    --optimizer=adam \\\n",
    "    --learning_rate=0.001 \\\n",
    "    --decay_scheme=luong234 \\\n",
    "    --metrics=bleu \\\n",
    "    --infer_mode=beam_search \\\n",
    "    --beam_width=5 \\\n",
    "    --num_gpus=1 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T11:15:11.887319Z",
     "iopub.status.busy": "2024-07-25T11:15:11.886992Z",
     "iopub.status.idle": "2024-07-25T11:15:13.849253Z",
     "shell.execute_reply": "2024-07-25T11:15:13.848128Z",
     "shell.execute_reply.started": "2024-07-25T11:15:11.887259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/kaggle/working/nmt/output.vi': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r /kaggle/working/nmt/output.vi\n",
    "!touch /kaggle/working/nmt/output.vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-07-25T11:15:13.850921Z",
     "iopub.status.busy": "2024-07-25T11:15:13.850680Z",
     "iopub.status.idle": "2024-07-25T11:15:26.656504Z",
     "shell.execute_reply": "2024-07-25T11:15:26.655770Z",
     "shell.execute_reply.started": "2024-07-25T11:15:13.850880Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\r\n",
      "For more information, please see:\r\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n",
      "  * https://github.com/tensorflow/addons\r\n",
      "If you depend on functionality not listed there, please file an issue.\r\n",
      "\r\n",
      "# Job id 0\r\n",
      "# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 1393690971757660448), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14822579076758432106), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 15261516715946852832), _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 15883691623, 13649834205340456019)]\r\n",
      "# Loading hparams from /kaggle/working/nmt/hparams\r\n",
      "# Vocab file /kaggle/input/en-vi-small/vocab.en exists\r\n",
      "# Vocab file /kaggle/input/en-vi-small/vocab.vi exists\r\n",
      "  attention=\r\n",
      "  attention_architecture=standard\r\n",
      "  avg_ckpts=False\r\n",
      "  batch_size=128\r\n",
      "  beam_width=5\r\n",
      "  best_bleu=10.225674864611175\r\n",
      "  best_bleu_dir=/kaggle/working/nmt/best_bleu\r\n",
      "  check_special_token=True\r\n",
      "  colocate_gradients_with_ops=True\r\n",
      "  coverage_penalty_weight=0.0\r\n",
      "  decay_scheme=luong234\r\n",
      "  dev_prefix=/kaggle/input/en-vi-small/val/tst2012\r\n",
      "  dropout=0.2\r\n",
      "  embed_prefix=None\r\n",
      "  encoder_type=bi\r\n",
      "  eos=</s>\r\n",
      "  epoch_step=527\r\n",
      "  forget_bias=1.0\r\n",
      "  infer_batch_size=32\r\n",
      "  infer_mode=beam_search\r\n",
      "  init_op=uniform\r\n",
      "  init_weight=0.1\r\n",
      "  language_model=False\r\n",
      "  learning_rate=0.001\r\n",
      "  length_penalty_weight=0.0\r\n",
      "  log_device_placement=False\r\n",
      "  max_gradient_norm=5.0\r\n",
      "  max_train=0\r\n",
      "  metrics=['bleu']\r\n",
      "  num_buckets=5\r\n",
      "  num_dec_emb_partitions=0\r\n",
      "  num_decoder_layers=2\r\n",
      "  num_decoder_residual_layers=0\r\n",
      "  num_embeddings_partitions=0\r\n",
      "  num_enc_emb_partitions=0\r\n",
      "  num_encoder_layers=2\r\n",
      "  num_encoder_residual_layers=0\r\n",
      "  num_gpus=1\r\n",
      "  num_inter_threads=0\r\n",
      "  num_intra_threads=0\r\n",
      "  num_keep_ckpts=5\r\n",
      "  num_sampled_softmax=0\r\n",
      "  num_train_steps=12000\r\n",
      "  num_translations_per_input=1\r\n",
      "  num_units=512\r\n",
      "  optimizer=adam\r\n",
      "  out_dir=/kaggle/working/nmt\r\n",
      "  output_attention=True\r\n",
      "  override_loaded_hparams=False\r\n",
      "  pass_hidden_state=True\r\n",
      "  random_seed=None\r\n",
      "  residual=False\r\n",
      "  sampling_temperature=0.0\r\n",
      "  share_vocab=False\r\n",
      "  sos=<s>\r\n",
      "  src=en\r\n",
      "  src_embed_file=\r\n",
      "  src_max_len=50\r\n",
      "  src_max_len_infer=None\r\n",
      "  src_vocab_file=/kaggle/input/en-vi-small/vocab.en\r\n",
      "  src_vocab_size=17192\r\n",
      "  steps_per_external_eval=None\r\n",
      "  steps_per_stats=1000\r\n",
      "  subword_option=\r\n",
      "  test_prefix=/kaggle/input/en-vi-small/test/tst2013\r\n",
      "  tgt=vi\r\n",
      "  tgt_embed_file=\r\n",
      "  tgt_max_len=50\r\n",
      "  tgt_max_len_infer=None\r\n",
      "  tgt_vocab_file=/kaggle/input/en-vi-small/vocab.vi\r\n",
      "  tgt_vocab_size=7710\r\n",
      "  time_major=True\r\n",
      "  train_prefix=/kaggle/input/en-vi-small/train/train\r\n",
      "  unit_type=lstm\r\n",
      "  use_char_encode=False\r\n",
      "  vocab_prefix=/kaggle/input/en-vi-small/vocab\r\n",
      "  warmup_scheme=t2t\r\n",
      "  warmup_steps=0\r\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Colocations handled automatically by placer.\r\n",
      "# Creating infer graph ...\r\n",
      "# Build a basic encoder\r\n",
      "  num_bi_layers = 1, num_bi_residual_layers=0\r\n",
      "  cell 0  LSTM, forget_bias=1WARNING:tensorflow:From /kaggle/working/nmt/nmt/model_helper.py:402: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\r\n",
      "  DeviceWrapper, device=/gpu:0\r\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\r\n",
      "WARNING:tensorflow:From /kaggle/working/nmt/nmt/model.py:843: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\r\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\r\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use tf.cast instead.\r\n",
      "WARNING:tensorflow:From /kaggle/working/nmt/nmt/model.py:445: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use tf.cast instead.\r\n",
      "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\r\n",
      "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\r\n",
      "WARNING:tensorflow:From /kaggle/working/nmt/nmt/model_helper.py:508: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\r\n",
      "  decoder: infer_mode=beam_searchbeam_width=5, length_penalty=0.000000, coverage_penalty=0.000000\r\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py:733: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use tf.cast instead.\r\n",
      "# Trainable variables\r\n",
      "Format: <name>, <shape>, <(soft) device placement>\r\n",
      "  embeddings/encoder/embedding_encoder:0, (17192, 512), /device:GPU:0\r\n",
      "  embeddings/decoder/embedding_decoder:0, (7710, 512), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\r\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 7710), \r\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use standard file APIs to check for files with this prefix.\r\n",
      "  loaded infer model parameters from /kaggle/working/nmt/translate.ckpt-12000, time 0.45s\r\n",
      "# Start decoding\r\n",
      "  decoding to output /kaggle/working/nmt/output.vi\r\n",
      "  done, num sentences 1268, num translations per input 1, time 7s, Thu Jul 25 13:09:23 2024.\r\n"
     ]
    }
   ],
   "source": [
    "!python -m nmt.nmt \\\n",
    "    --out_dir=/kaggle/working/nmt \\\n",
    "    --inference_input_file=/kaggle/input/en-vi-small/test/tst2013.en \\\n",
    "    --inference_output_file=/kaggle/working/nmt/output.vi \\\n",
    "    --src=en --tgt=vi \\\n",
    "    --vocab_prefix=/kaggle/input/en-vi-small/vocab \\\n",
    "    --ckpt=/kaggle/working/nmt/translate.ckpt-12000 \\\n",
    "    --infer_mode=beam_search \\\n",
    "    --beam_width=5 \\\n",
    "    --nums_gpu=1 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-07-25T11:15:26.658715Z",
     "iopub.status.busy": "2024-07-25T11:15:26.658355Z",
     "iopub.status.idle": "2024-07-25T11:15:26.673254Z",
     "shell.execute_reply": "2024-07-25T11:15:26.672480Z",
     "shell.execute_reply.started": "2024-07-25T11:15:26.658654Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: We Western donor countries have given the African continent two trillion American dollars in the last 50 years . \n",
      "Predict: Chúng ta phương Tây đã bán 50 % dân số thế giới với 50 % trong 50 năm vừa qua . \n",
      "Target: Chúng ta , những quốc gia viện trợ Tây Phương đã mang đến lục địa Châu Phi 2 tỉ tỉ Mỹ Kim trong vòng 50 năm qua .\n",
      "\n",
      "Source: When something becomes ultra-low cost , it becomes massively scalable . \n",
      "Predict: <unk> một cái gì đó trở nên tồi tệ , nó sẽ trở nên rộng lớn hơn <unk> \n",
      "Target: Khi một cái gì đó trở nên cực rẻ , nó sẽ được phổ biến trên diện rộng\n",
      "\n",
      "Source: I &apos;m confident that you will see more and more North Koreans succeeding all over the world , including the TED stage . \n",
      "Predict: <unk> đã tin rằng tôi sẽ làm bất cứ điều gì trong cộng đồng của Ấn Độ và Ấn Độ , các công ty truyền hình thành phố <unk> \n",
      "Target: Tôi tin tưởng rằng các bạn sẽ nhìn thấy ngày càng nhiều người Bắc Triều Tiên thành công ở mọi nơi trên thế giới , kể cả trên sân khấu của TED\n",
      "\n",
      "Source: Am I South Korean or North Korean ? \n",
      "Predict: Tôi là Bắc Hàn hay Hàn Quốc ? \n",
      "Target: Tôi là người Nam Triều Tiên hay Bắc Triều Tiên ?\n",
      "\n",
      "Source: But self-determination and living in the digital age is no contradiction . \n",
      "Predict: Nhưng sự sống và sự sống trong thời đại của chúng ta không còn tồn tại . \n",
      "Target: Sự tự chủ và việc sống trong thời đại công nghệ số không hề mâu thuẫn .\n",
      "\n",
      "Source: But you have to fight for your self-determination today . \n",
      "Predict: Nhưng bạn phải đấu tranh cho <unk> ngày hôm nay . \n",
      "Target: Điều mà bạn nên làm là đấu tranh cho sự tự chủ của mình ngày hôm nay .\n",
      "\n",
      "Source: And he very clearly explained to me that emotional displays are very dangerous in a place like this , not just for me , but for them . \n",
      "Predict: Và ông ấy đã giải thích rõ ràng rằng tôi cho thấy một bức tranh rất nguy hiểm đối với tôi là không thể dễ bị tổn thương . \n",
      "Target: Ông giải thích rất rõ rằng thể hiện cảm xúc là rất nguy hiểm ở nơi như thế này , không phải với tôi , mà với họ .\n",
      "\n",
      "Source: The North Korean authorities intercepted some money that I sent to my family , and , as a punishment , my family was going to be forcibly removed to a desolate location in the countryside . \n",
      "Predict: <unk> những nhà tài trợ tài trợ cho một người bạn của tôi ở Bắc Triều tiên , đó là những gì tôi đã làm , và một gia đình tôi đang ở trong khu vực lân cận quốc gia Yellowstone <unk> \n",
      "Target: Chính quyền Bắc Triều Tiên đã phát hiện ra số tiền mà tôi gửi về cho gia đình , và , để trừng phạt , họ sẽ bắt gia đình tôi phải chuyển về một vùng bị cách ly ở nông thôn .\n",
      "\n",
      "Source: The worst part is putting this sweater over my head , because that &apos;s when you &apos;ll all laugh at me , so don &apos;t do anything while it &apos;s over my head . \n",
      "Predict: Điều tồi tệ nhất là tai nạn xe của tôi như thế này , bởi vì tôi nói với bạn rằng tôi không làm gì hết lần đầu tiên . \n",
      "Target: Phần tệ nhất là tròng cái áo dài tay này qua đầu bởi vì thể nào quí vị cũng cười tôi , vậy nên đừng làm gì hết khi nó ở trên đầu tôi .\n",
      "\n",
      "Source: They are far from being extinct . \n",
      "Predict: Chúng từ rất xa xưa . \n",
      "Target: Họ còn lâu mới bị tuyệt chủng .\n",
      "\n",
      "Source: All this is possible with this information . \n",
      "Predict: Tất cả những điều này có thể xảy ra với thông tin này . \n",
      "Target: Tất cả đều có thể với những thông tin này .\n",
      "\n",
      "Source: So the city planners , they get together and they figure they &apos;re going to change the name South Central to make it represent something else , so they change it to South Los Angeles , like this is going to fix what &apos;s really going wrong in the city . \n",
      "Predict: <unk> vậy , những nhà hoạch định , họ thay đổi , và họ sẽ thay đổi thế giới , họ sẽ chuyển sang thành phố như thế này , và họ sẽ thay đổi nó tại một nơi nào đó , nó sẽ được đưa ra từ một thành phố \n",
      "Target: Vì vậy các nhà hoạch định thành phố họp lại với nhau và họ định thay cái tên Nam Trung để nó mang ý nghĩa khác . Vậy nên họ đổi thành vùng Nam Los Langeles , như thể việc đó sẽ giải quyết được những rắc rối đang thực sự diễn ra trong thành phố .\n",
      "\n",
      "Source: We have groups of volunteers supporting the Enterprise Facilitator to help you to find resources and people and we have discovered that the miracle of the intelligence of local people is such that you can change the culture and the economy of this community just by capturing the passion , the energy and imagination of your own people . \n",
      "Predict: <unk> tôi có những nhóm các tổ chức kinh doanh truyền thống , người ta có thể tìm thấy sự thay đổi lớn lao và giúp chúng ta hiểu được những điều mà bạn có thể tìm thấy trong cộng đồng của họ và những ý tưởng của những người có thể tìm kiếm những \n",
      "Target: Chúng tôi có những nhóm tình nguyện viên trợ giúp cho Enterprise Facilitator họ giúp tìm kiếm những nguồn tài nguyên và con người và chúng tôi khám phá ra rằng cái phép lạ từ trí thông minh của người bản địa như cái gì đó giống như là bạn có thể thách thức nền văn hoá và kinh tế của cộng đồng này chỉ bằng cách nắm được cái khát vọng , nguồn năng lượng và trí tưởng tượng như thể của người dân của bạn\n",
      "\n",
      "Source: I made this last year , and started receiving hundreds of messages from passionate people who wanted to make a wall with their community , so my civic center colleagues and I made a tool kit , and now walls have been made in countries around the world , including Kazakhstan , South Africa , Australia , Argentina and beyond . \n",
      "Predict: <unk> đã bắt đầu từ năm ngoái , và tôi đã bắt đầu chia sẻ tất cả những người trong cộng đồng , và tạo ra một bức tranh cộng đồng với những người lính cứu hoả từ khắp nơi trên thế giới , đã được xây dựng bởi <unk> <unk> , Ấn Độ và Nhật Bản \n",
      "Target: Tôi làm dự án này năm ngoái , và bắt đầu nhận được hàng trăm lá thư từ những người nhiệt thành những người muốn làm một bức tường ở cộng đồng của họ , vì vậy các đồng nghiệp dân cư trung tâm và tôi làm một công cụ , và bây giờ những bức tường đã đang được làm ở các đất nước trên thế giới , bao gồm Kazakhstan , Nam Phi , Úc , Ác-hen-ti-na và nhiều hơn nữa .\n",
      "\n",
      "Source: You have to fight for it every day . \n",
      "Predict: Bạn phải chiến đấu với nó mỗi ngày . \n",
      "Target: Và bạn phải đấu tranh không ngừng nghỉ cho nó mỗi ngày .\n",
      "\n",
      "Source: Even though they were caught , they were eventually released after heavy international pressure . \n",
      "Predict: <unk> sau đó , họ đã bị bắt giữ , họ đã thu được nhiều nước sạch hơn <unk> \n",
      "Target: vì mặc dù đã bị bắt , nhưng cuối cùng học cũng được thả ra nhờ vào sức ép từ cộng đồng quốc tế .\n",
      "\n",
      "Source: Thanks . \n",
      "Predict: Cảm ơn . \n",
      "Target: Cảm ơn\n",
      "\n",
      "Source: So I was living in constant fear that my identity could be revealed , and I would be repatriated to a horrible fate back in North Korea . \n",
      "Predict: <unk> vậy , tôi đã sống trong sự xấu hổ của sự tự do của mình , tôi có thể tự hỏi rằng mình sẽ không còn tồn tại trong một vũ trụ nhỏ trong một thời gian dài <unk> \n",
      "Target: Tôi luôn sống trong một nỗi sợ thường trực rằng danh tính của tôi sẽ bị phát hiện , và tôi sẽ bị trả về với cuộc sống cũ ở Bắc Triều Tiên .\n",
      "\n",
      "Source: We had a victory on our hands . \n",
      "Predict: Chúng tôi đã giành chiến thắng . \n",
      "Target: Chúng tôi đã có được một chiến thắng trong tay .\n",
      "\n",
      "Source: Wrong . They were all enslaved . \n",
      "Predict: Sai . Họ là những viên đạn . \n",
      "Target: Sai . Họ đều bị nô lệ .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "with open('/kaggle/working/nmt/output.vi', 'r') as file:\n",
    "    preds = file.readlines()\n",
    "\n",
    "with open('/kaggle/input/en-vi-small/test/tst2013.en', 'r') as file:\n",
    "    src = file.readlines()\n",
    "\n",
    "with open('/kaggle/input/en-vi-small/test/tst2013.vi', 'r') as file:\n",
    "    trg = file.readlines()\n",
    "\n",
    "result = list(zip(src, trg, preds))\n",
    "\n",
    "# In ra 20 cặp ví dụ dự đoán ngẫu nhiên\n",
    "sample_indices = random.sample(range(len(result)), 20)\n",
    "for i in sample_indices:\n",
    "    print(f\"Source: {result[i][0].strip()} \\n\"\n",
    "          f\"Predict: {result[i][2].strip()} \\n\"\n",
    "          f\"Target: {result[i][1].strip()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T11:25:51.791453Z",
     "iopub.status.busy": "2024-07-25T11:25:51.791152Z",
     "iopub.status.idle": "2024-07-25T11:25:51.800454Z",
     "shell.execute_reply": "2024-07-25T11:25:51.799533Z",
     "shell.execute_reply.started": "2024-07-25T11:25:51.791410Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def translate_sentence(sentence):\n",
    "    # Tạo thư mục tmp nếu chưa tồn tại\n",
    "    os.makedirs('/kaggle/working/tmp', exist_ok=True)\n",
    "\n",
    "    # Ghi câu đầu vào vào file\n",
    "    with open('/kaggle/working/tmp/input.en', 'w', encoding='utf-8') as f:\n",
    "        f.write(sentence)\n",
    "\n",
    "    command = [\n",
    "        \"python\", \"-m\", \"nmt.nmt\",\n",
    "        \"--out_dir=/kaggle/working/nmt\",\n",
    "        \"--inference_input_file=/kaggle/working/tmp/input.en\",\n",
    "        \"--inference_output_file=/kaggle/working/tmp/output.vi\",\n",
    "        \"--src=en\", \"--tgt=vi\",\n",
    "        \"--vocab_prefix=/kaggle/input/en-vi-small/vocab\",\n",
    "        \"--ckpt=/kaggle/working/nmt/translate.ckpt-12000\",\n",
    "        \"--infer_mode=beam_search\",\n",
    "        \"--beam_width=5\",\n",
    "        \"--num_translations_per_input=5\",\n",
    "        \"--nums_gpu=1\",\n",
    "        \"--quiet\"\n",
    "    ]\n",
    "\n",
    "    subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    # Đọc kết quả từ file output\n",
    "    with open('/kaggle/working/tmp/output.vi', 'r', encoding='utf-8') as f:\n",
    "        prediction = f.read().strip()\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T11:27:20.070269Z",
     "iopub.status.busy": "2024-07-25T11:27:20.069924Z",
     "iopub.status.idle": "2024-07-25T11:27:26.001341Z",
     "shell.execute_reply": "2024-07-25T11:27:26.000212Z",
     "shell.execute_reply.started": "2024-07-25T11:27:20.070206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: You are my sunshine .\n",
      "Translation: Các bạn là gió của tôi .\n",
      "Các bạn là gió .\n",
      "Các bạn có gió .\n",
      "Các bạn kiên nhẫn với tôi .\n",
      "Các bạn là ánh nắng của tôi .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"You are my sunshine .\"\n",
    "translation = translate_sentence(sentence)\n",
    "print(f\"Input: {sentence}\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5054116,
     "sourceId": 9031239,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 23026,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
